+++
title = "WAZE Syndrome and Bias Sensitivity"
date = 2024-03-06
updated = 2024-03-12
description = "Recognizing the limitations of generative artificial intelligences is a first step towards an enlightened and critical use of these technologies. Indeed, the apparent efficiency and convenience offered by these systems must not overshadow the imperative need for constant vigilance. Users must arm themselves with critical thinking and an increased awareness of the ethical ramifications of AI usage."

[taxonomies]
tags = ["AI", "bias", "Responsible AI", "AI Sovereignty"]

[extra]
giscus = true
copy_button = true
footnote_backlinks = true
+++


<div style="overflow: auto;">
    <img src="/blog/waze-syndrome/img/waze.png" style="float: left; margin-top: 20px; margin-right: 20px; width: 30%; vertical-align: top;">
    <div style="display: block;">
        <p>I recently gave an introductory AI course to a Bachelor's degree class at the University of Cergy (France), where the topic of discussion was how AI could influence human decision-making capabilities and free will. The comparison of how we use Waze, and navigation apps in general, is telling: today, we blindly trust these applications! They are efficient most of the time, so we stop thinking and never fail to turn them on for even the shortest journeys. But perhaps they lead us on paths that serve interests other than just getting us efficiently from point A to point B. Maybe they have us miss certain gas stations or other points of interest that could be beneficial or more economical for us. This reliance raises questions about whether we are ceding too much control to these algorithms, potentially overlooking alternative routes or experiences that could offer more than just efficiency. Such scenarios underscore the importance of maintaining a balance between leveraging technological conveniences and retaining our ability to make independent and informed decisions.</p>
    </div>
</div>

The 'WAZE Syndrome' is a metaphor describing our tendency to blindly follow technologies, especially those claiming to simplify our decision-making processes, like the WAZE navigation app. This syndrome may extend to our interactions with generative artificial intelligences (such as GPT-4, DALL-E, etc.), which are trained on vast data sets and produce content that appears persuasive.

Generative AIs, though sophisticated, are not free from bias. These biases may stem from the selection of training data, how algorithms interpret this data, and the implicit or explicit objectives of those who develop and utilize them. For instance, if an AI is predominantly trained on data from Western sources, it might not be representative of diverse global perspectives.

By delegating our thinking and decision-making to these systems, we risk being subtly influenced by these biases. This can insidiously shape our worldview and values. For example, if a generative AI predominantly produces images in a style aligning with certain aesthetic standards, users may subconsciously start to favor those standards over others. Similarly, if a generative AI writes primarily in a particular style or tone, it could influence how users expect information to be presented, potentially excluding styles that might be more nuanced or accurate in some contexts.

Understanding AI bias sensitivity is important for responsible use. It is vital to question the results provided by AI, understand the limits of these technologies, and recognize that our own judgment remains an integral part of the decision-making process. This requires continuous education on how AIs function, their strengths and weaknesses, and a commitment to diversifying the datasets and perspectives incorporated into the AI development process.

It becomes essential to cultivate advanced digital literacy, where the user is not just a consumer of technology but also a conscious actor in its influence. This involves developing the ability to question and evaluate the information produced by AI, to recognize the subtle inflections of present biases, and to appreciate the multitude of perspectives that humans can (still) offer compared to the machine. Instead of being unreservedly guided by AI suggestions, a stance of critical collaboration should be adopted, where humans guide AI as much as AI assists humans.

This synergy between human and artificial intelligence must be fostered with discernment to avoid falling into a technological dependence where human judgment is neglected.

